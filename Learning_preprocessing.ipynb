{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Preprocessing\n",
    " \n",
    "Les opérations du preprocessing:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encodage :  consiste à convertir les données qualitatives en valeur numérique\n",
    "\n",
    "Normalisation : qui consiste à mettre sur une même échelle les valeurs quantitative\n",
    "\n",
    "Imputation : Remplacer les données manquantes par certaines valeurs statistiques\n",
    "\n",
    "Selection de variable : Utilise les tests statistiques pour sélectionner les variables les plus utiles au développement d'un modèle\n",
    "\n",
    "Extration de caractéristique : Génerer des nouvelles variables à partir des informations cachées dans le dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les modules de scikit-learn pour ces opérations:\n",
    "\n",
    "Encodage et Normalisation : <span style=\"color:red;\"> sklearn.preprocessing</span>\n",
    "\n",
    "Imputation : <span style=\"color:red;\">sklearn.impute</sapan>\n",
    "\n",
    "Selection de variable : <span style=\"color:red;\">sklearn.feature_selection</sapan>\n",
    "\n",
    "Extration de caractéristique : <span style=\"color:red;\">sklearn.feature_extraction</sapan>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sklearn.preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le module preprocessing on retrouve des classes transformers commençant toutes par la lettre majuscule.\n",
    "exemple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les transformers permettent de transformer l'ensemble de nos données de façon cohérente en transformant toutes nos données futures de la même manière qu'ont été transformées les données qui ont servit à l'entrainement de la machine grâce à 2 méthodes:\n",
    "<ul>\n",
    "<il>fit : Développer une fonction de transformation en analysant les données du trainset</il> \n",
    "<il>transform : Appliquer cette fonction de transformation sur toutes les données qu'on lui fournit</il>\n",
    "</ul>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "et des fonctions mathématiques . exemple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import minmax_scale"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Les tranformers de l'encodage\n",
    "\n",
    "il existe 2 types d'encodage: Ordinal et One-Hot\n",
    "\n",
    "L'encodage ordinal: consiste à associer chaque classe à une valeur décimal unique.\n",
    "exemple : Chat --> 0 et Chien --> 1\n",
    "On dispose  des transformers:\n",
    "LabelEncoder() et OrdinalEncoder()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### LabelEncoder()\n",
    "a été conçu pour encoder la variable y en une valeur numérique (0, n_classe-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classes_': array(['Chat', 'Chien', 'Oiseau'], dtype='<U6')}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 0, 2])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "y = np.array(['Chien', 'Chat', 'Oiseau', 'Chat', 'Chat','Chien'])\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y)\n",
    "\n",
    "print(encoder.__dict__)\n",
    "\n",
    "encoder.transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Chat', 'Chien', 'Chat', 'Chat', 'Oiseau', 'Oiseau', 'Chien'],\n",
       "      dtype='<U6')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# La méthode inverse_transform permet de decoder\n",
    "encoder.inverse_transform(np.array([0, 1, 0, 0, 2, 2, 1]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### OrdinalEncoder\n",
    "permet d'encoder les tableaux à plusieurs dimensions, utiliser pour encoder les features X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1.],\n",
       "       [2., 0.],\n",
       "       [0., 1.],\n",
       "       [2., 0.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "X = np.array([['Chien', 'poils'], ['Oiseau', 'plumes'], ['Chat', 'poils'], ['Oiseau', 'plumes']])\n",
    "encoder = OrdinalEncoder()\n",
    "encoder.fit(X)\n",
    "encoder.transform(X)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:red;\"> Encodage Ordinal à un souci car transformer des données en des valeurs ordinales peut mener à une comparaison où 0 <1<2 autrement dire Chat < Chien < Oiseau </span>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour résoudre ce problème nous avons l'encodage one-hot"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encodage One-Hot\n",
    "\n",
    "Les classes sont:\n",
    "#### LabelBinarizer()\n",
    "#### MultiLabelBinarizer()\n",
    "#### OneHotEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg_label': 0, 'pos_label': 1, 'sparse_output': False, 'y_type_': 'multiclass', 'sparse_input_': False, 'classes_': array(['Chat', 'Chien', 'Oiseau'], dtype='<U6')}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "y = np.array(['Chien', 'Chat', 'Oiseau', 'Chat', 'Chat','Chien'])\n",
    "\n",
    "encoder = LabelBinarizer()\n",
    "encoder.fit(y)\n",
    "\n",
    "print(encoder.__dict__)\n",
    "\n",
    "encoder.transform(y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalisation\n",
    "\n",
    "Mettre toutes les données sur une même échelle."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les techniques de Normalisation les plus connus sont :"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MinMaxScaler"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transforme chaque variable X de telle sorte à être comprise entre 0 et 1:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    " \\frac{{X - X_{\\text{min}}}}{{X_{\\text{max}} - X_{\\text{min}}}}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0. ],\n",
       "       [0.2],\n",
       "       [1. ]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "X = np.array([[70], [80], [120]])\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit_transform(X)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### StandardScaler"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chaque variable X : La moyenne qui est égale à O et l'écart type égal à 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La formule de la StandardScaler de scikit-learn est donnée par :\n",
    "\n",
    "\\[\n",
    "X_{\\text{scaled}} = \\frac{X - \\mu}{\\sigma}\n",
    "\\]\n",
    "\n",
    "où :\n",
    "- \\( X_{\\text{scaled}} \\) est la matrice des données transformées (centrées et réduites).\n",
    "- \\( X \\) est la matrice originale des données.\n",
    "- \\( \\mu \\) est le vecteur moyen (moyenne) des colonnes de \\( X \\).\n",
    "- \\( \\sigma \\) est le vecteur écart-type des colonnes de \\( X \\).\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NB : Eviter d'utiliser MinMax ou standard lorsque nous sommes en présence d'un outilier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pour cela nous alons utiliser le troisième transfomer :"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RobustScaler"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La formule de RobustScaler de scikit-learn est donnée par :\n",
    "\n",
    "\\[ X_{\\text{scaled}} = \\frac{{X - Q_1(X)}}{{Q_3(X) - Q_1(X)}} \\]\n",
    "\n",
    "où :\n",
    "- \\( X_{\\text{scaled}} \\) est la matrice des données transformées (robustes).\n",
    "- \\( X \\) est la matrice originale des données.\n",
    "- \\( Q_1(X) \\) représente le premier quartile (25e percentile) de chaque colonne de \\( X \\).\n",
    "- \\( Q_3(X) \\) représente le troisième quartile (75e percentile) de chaque colonne de \\( X \\).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
